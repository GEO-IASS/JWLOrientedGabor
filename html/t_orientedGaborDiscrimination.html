
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>t_orientedGaborDiscrimination</title><meta name="generator" content="MATLAB 8.5"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2016-02-09"><meta name="DC.source" content="t_orientedGaborDiscrimination.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">t_orientedGaborDiscrimination</a></li><li><a href="#2">Specify parameters for contrast values and noise repititions</a></li><li><a href="#3">Initialize the optics and the sensor</a></li><li><a href="#4">Loop over two stimulus classes and repeated trials and compute cone responses</a></li><li><a href="#6">Train linear SVM and find cross-validated accuracy</a></li><li><a href="#8">Save</a></li><li><a href="#9">Classifiy</a></li><li><a href="#10">Plot classification accuracy as function of convergence ratio</a></li></ul></div><h2>t_orientedGaborDiscrimination<a name="1"></a></h2><p>Model cone responses for the experiment on measuring orientation discrimination thresholds of an acrhomatic, peripheral Gabor by Marisa Carrasco and Jon Winawer.</p><p>Script outline:     1. Build scene as an achromatic Gabor patch with imageHarmonic.     2. Build oi and sensor with specified properties (eccentricity, etc.)     3. Loop over 2 stimulus orientations and n trials per orientation     4. Within each trial, add eye movements to sensor     5. Build the outer segment object with linear filters and compute its         response with the sensor structure.     6. Sum the response over time for each cone as a cheap way to simulate          downstream temporal integration of cone outputs     7. Save the cone response as they are time consuming to compute     8. From the saved cone file, compute simplified RGC outputs by           convolution (DoG) and subsampling     9. Compute linear discriminant of stimulus orientation using cone           outputs and RGC outputs</p><p>JRG/NC/BW ISETBIO Team, Copyright 2015</p><pre class="codeinput">clear
ieInit

plotConeResponseFlag = true; <span class="comment">% plot an example movie of cone responses during one trial</span>
saveConeCurrentsFlag = true;  <span class="comment">% save cone responses across all trials (after temporal integration within trials)</span>
</pre><h2>Specify parameters for contrast values and noise repititions<a name="2"></a></h2><pre class="codeinput"><span class="comment">% Specify angles of Gabor stimulus orientation</span>
angleArr = (pi/180)*[-20 20]; nAngles = length(angleArr);

<span class="comment">% Specify retinal location where stimulus is presented (6 deg above fovea)</span>
locationRadius = 6; <span class="comment">% degrees of visual angle</span>
locationAngle  = 0; <span class="comment">% degrees of polar angle (0 is vertical)</span>

<span class="comment">% Number of trials per stimulus condition</span>
nTrials        = 50;

<span class="comment">% Eye movement function handle</span>
<span class="comment">%   random jitter</span>
fun{1} = @(n) randn(n, 2)*2;
<span class="comment">%   directional drift</span>
fun{2} = @(n) (1:n)' * [1 0];
<span class="comment">%   square wave oscillation</span>
fun{3} = @(n) square((1:n)/params.n*2*pi*5)' * [1 0];
eyePosFun = fun{1};

<span class="comment">% Basic human optics parameters.</span>
oi  = oiCreate(<span class="string">'wvf human'</span>);
</pre><h2>Initialize the optics and the sensor<a name="3"></a></h2><pre class="codeinput"><span class="comment">% Set parameters for building the scene/oi/sensor The</span>
<span class="comment">% stimulus consists of an achromatic Gabor patch at +/- 20 deg.</span>

<span class="comment">% stimulus parameters</span>
<span class="comment">%params            = paramsGaborColorOpponent();</span>

params.fov           = 1.5;            <span class="comment">% Gabor is windowed with 1.5 deg aperture</span>
params.freq          = 6*params.fov;   <span class="comment">% ... and has spatial frequency of 6 cpd</span>
params.GaborFlag     = .25/params.fov; <span class="comment">% ... and std of .25 deg</span>
params.nSteps        = 100;            <span class="comment">% 100 time steps (1 ms sampling)</span>
params.ecc           = 6;              <span class="comment">% 6 degrees eccentricity</span>
params.contrast      = .25;            <span class="comment">% Max contrat of 0.25</span>
params.expTime       = 0.001;
params.timeInterval  = 0.001;
params.meanLuminance = 100;

<span class="comment">% We build a dummy scene here just so we can subsequently calculate</span>
<span class="comment">% the sensor size.  But this scene itself is not used.  Rather we</span>
<span class="comment">% build the scene below.</span>
scene = sceneCreate(<span class="string">'harmonic'</span>, params);
scene = sceneSet(scene, <span class="string">'h fov'</span>, params.fov);


coneP = coneCreate; <span class="comment">% The cone properties properties</span>

sensor = sensorCreate(<span class="string">'human'</span>, coneP, [locationRadius(1) locationAngle(1)]);
sensor = sensorSetSizeToFOV(sensor, params.fov, scene, oi);
sensor = sensorSet(sensor, <span class="string">'exp time'</span>, params.expTime); <span class="comment">% 1 ms</span>
sensor = sensorSet(sensor, <span class="string">'time interval'</span>, params.timeInterval); <span class="comment">% 1 ms</span>

<span class="comment">% This computes with sensor and photon noise</span>
sensor = sensorSet(sensor,<span class="string">'noise flag'</span>,2);
</pre><h2>Loop over two stimulus classes and repeated trials and compute cone responses<a name="4"></a></h2><pre class="codeinput">storedConeCurrents = cell(1,nAngles);

<span class="keyword">for</span> angleInd = 1:nAngles
     <span class="comment">% fprintf('\n'); % Comment out for publishing</span>

    <span class="comment">% We render a new scene for each stimulus orientation (but not for</span>
    <span class="comment">% repeated trials for the same orientation). We also pad the scene</span>
    <span class="comment">% field of view by factor padFactor so that eye movements do not cause</span>
    <span class="comment">% the sensor to move out of the scence field of view</span>
    padFactor             = 2;
    theseParams           = params;
    theseParams.ang       = angleArr(angleInd);
    theseParams.freq      = params.freq * padFactor;
    theseParams.GaborFlag = params.GaborFlag / padFactor;

    scene = sceneCreate(<span class="string">'harmonic'</span>, theseParams);
    scene = sceneSet(scene, <span class="string">'h fov'</span>, params.fov*padFactor);

    <span class="comment">% Compute optical image - also computed once per stimulus class (not</span>
    <span class="comment">% re-computed for new trials within a stimulus class)</span>
    oi = oiCompute(oi, scene);

    <span class="comment">% Loop over trials. Each trial gets its own eye movments.</span>
    <span class="keyword">for</span> trial = 1:nTrials
</pre><pre class="codeinput">        <span class="comment">% fprintf('.'); drawnow();  % Comment out for publishing</span>

        <span class="comment">% Eye position in units of number of cones</span>
        eyePos = eyePosFun(params.nSteps);

        <span class="comment">% Loop through frames to build movie</span>
        volts = zeros([sensorGet(sensor, <span class="string">'size'</span>) params.nSteps]);
        <span class="keyword">for</span> t = 1 : params.nSteps

            <span class="comment">% Compute absorptions</span>
            sensor = sensorSet(sensor, <span class="string">'positions'</span>, eyePos(t, :));
            sensor = coneAbsorptions(sensor, oi);

            volts(:,:,t) = sensorGet(sensor, <span class="string">'volts'</span>);
        <span class="keyword">end</span> <span class="comment">% t</span>

        <span class="comment">% Set the stimuls into the sensor object</span>
        sensor = sensorSet(sensor, <span class="string">'volts'</span>, volts);
</pre><h2>Train linear SVM and find cross-validated accuracy<a name="6"></a></h2><p>Create the outer segment object</p><pre class="codeinput">        os = osCreate(<span class="string">'linear'</span>);

        <span class="comment">% Compute the photocurrent for the whole time series</span>
        os = osCompute(os, sensor);
        coneCurrentSignal = sum(osGet(os, <span class="string">'conecurrentsignal'</span>),3);
        params.coneArraySize = size(coneCurrentSignal);

        storedConeCurrents{angleInd}(trial,:) = coneCurrentSignal(:);

        <span class="comment">% visualize cone response for an example trials</span>
        <span class="keyword">if</span> plotConeResponseFlag &amp;&amp; trial == 1
            vcAddObject(scene); sceneWindow;

            vcNewGraphWin;
            coneCurrentSignal = osGet(os, <span class="string">'conecurrentsignal'</span>);

            subplot(3,1,1)
            imagesc(mean(coneCurrentSignal,3));axis <span class="string">image</span>
            title(<span class="string">'Mean cone output across trial'</span>);
            <span class="keyword">for</span> ii = 1:params.nSteps
                subplot(3,1,2)
                imagesc(coneCurrentSignal(:,:,ii)); axis <span class="string">image</span>
                title(<span class="string">'Cone output at single time points'</span>);
                subplot(3,1,3)
                imagesc(volts(:,:,ii));  axis <span class="string">image</span>
                title(<span class="string">'Cone voltage at single time points'</span>);
                pause(0.1);
            <span class="keyword">end</span> <span class="comment">% nSteps</span>
        <span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="t_orientedGaborDiscrimination_01.png" alt=""> <img vspace="5" hspace="5" src="t_orientedGaborDiscrimination_02.png" alt=""> <img vspace="5" hspace="5" src="t_orientedGaborDiscrimination_03.png" alt=""> <img vspace="5" hspace="5" src="t_orientedGaborDiscrimination_04.png" alt=""> <pre class="codeinput">    <span class="keyword">end</span>

<span class="keyword">end</span> <span class="comment">%angleInd</span>
</pre><h2>Save<a name="8"></a></h2><pre class="codeinput">coneData = [storedConeCurrents{1}; storedConeCurrents{2}];
labels   = [ones(nTrials,1); -1*ones(nTrials,1)];

dataPth = fullfile(fileparts(which(mfilename)), <span class="string">'data'</span>);

<span class="keyword">if</span> saveConeCurrentsFlag
    fname = fullfile(dataPth, sprintf(<span class="string">'coneResponses%s.mat'</span>, datestr(now, <span class="string">'YYYY-mm-DD_HH.MM.SS'</span>)));
    save(fname,  <span class="string">'coneData'</span>, <span class="string">'labels'</span>, <span class="string">'params'</span>, <span class="string">'eyePosFun'</span>);
<span class="keyword">end</span>
</pre><h2>Classifiy<a name="9"></a></h2><pre class="codeinput">d = dir(fullfile(dataPth, <span class="string">'*.mat'</span>));
[~,idx] = sort([d.datenum]);

load(fullfile(dataPth, d(idx(end)).name));

<span class="comment">% Fit a linear svm classifier between two orientations and calculate</span>
<span class="comment">% cross-validated accuracy based on model</span>

<span class="comment">% -------- first for cone signals ---------------------------------------</span>
m = fitcsvm(coneData, labels, <span class="string">'KernelFunction'</span>, <span class="string">'linear'</span>);
cv = crossval(m,<span class="string">'kfold'</span>,5);
rocAreaCones = 1-kfoldLoss(cv);

<span class="comment">% -------- then for RGC signals -----------------------------------------</span>
<span class="comment">%  RGC hack - bandpass filter and subsample</span>

<span class="comment">% RGC is a strucutred array. Each element corresponds to one model of RGCs.</span>
<span class="comment">% The model is defined by a spatial receptive field 'rf' and a subsampling</span>
<span class="comment">% rate 'ss'. The output of the RGCs are stored in 'data'. The inputs come</span>
<span class="comment">% from the cone outputs.</span>
rgc = struct(<span class="string">'ss'</span>, [], <span class="string">'rf'</span>, [], <span class="string">'data'</span>, []);

<span class="comment">% We will make several RGC classes defined by scaleFactor, which will scale</span>
<span class="comment">% both the receptive field size and the subsampling rate (the bigger the</span>
<span class="comment">% RF, the more coarsely we subsample).</span>
scaleFactor = linspace(2,4,4);
<span class="keyword">for</span> ii = 1:length(scaleFactor)
    <span class="comment">% Center surround RF. The receptive fields have an excitatory center</span>
    <span class="comment">% with std of 1 cone * scaleFactor. The inhibitory surround has twice</span>
    <span class="comment">% the sd of the center. The cell is balanced, so that the sum of center</span>
    <span class="comment">% minus surround = 0.</span>
    rfCenter   = fspecial(<span class="string">'Gaussian'</span>, 20,scaleFactor(ii));
    rfSurround = fspecial(<span class="string">'Gaussian'</span>, 20,2*scaleFactor(ii));
    rgc(ii).rf =  rfCenter - rfSurround;
    rgc(ii).subsample = scaleFactor(ii);
<span class="keyword">end</span>

<span class="comment">%  Load stored cone data</span>
coneData = reshape(coneData, [], params.coneArraySize(1), params.coneArraySize(2));


<span class="comment">%  Loop across RGC types</span>
nBtsrp = 20;
rocAreaRGC = NaN(nBtsrp, length(rgc));
<span class="keyword">for</span> ii = 1:length(rgc)
    ss  = rgc(ii).subsample;
    rf  = rgc(ii).rf;

    <span class="comment">% Loop across trials, extracting RGC signals by convolution + subsample</span>
    <span class="keyword">for</span> trial = 1:size(coneData,1)
        coneCurrentSignal = squeeze(coneData(trial,:,:));
        tmp = conv2(coneCurrentSignal,rf, <span class="string">'valid'</span>);
        tmp = tmp(round(ss:ss:end),round(ss:ss:end));
        rgc(ii).data(trial,:) = tmp(:);
    <span class="keyword">end</span>

    <span class="comment">% Classify RGC outputs</span>
    <span class="keyword">for</span> btstrp = 1:nBtsrp
        <span class="comment">% scrambled = labels(randperm(length(labels)));</span>
        m = fitcsvm(rgc(ii).data, labels, <span class="string">'KernelFunction'</span>, <span class="string">'linear'</span>);
        cv = crossval(m,<span class="string">'kfold'</span>,5);
        rocAreaRGC(btstrp, ii) = 1-kfoldLoss(cv);
    <span class="keyword">end</span>
<span class="keyword">end</span>

fprintf(<span class="string">'ROC Area for cones: %4.2f\n'</span>, rocAreaCones)
<span class="keyword">for</span> ii = 1:length(rgc);
    fprintf(<span class="string">'ROC Area for RGC class %d: %4.2f\n'</span>, ii, mean(rocAreaRGC(:,ii)))
<span class="keyword">end</span>
</pre><pre class="codeoutput">ROC Area for cones: 0.88
ROC Area for RGC class 1: 0.88
ROC Area for RGC class 2: 0.77
ROC Area for RGC class 3: 0.58
ROC Area for RGC class 4: 0.58
</pre><h2>Plot classification accuracy as function of convergence ratio<a name="10"></a></h2><pre class="codeinput">fH = vcNewGraphWin;
set(fH, <span class="string">'Color'</span>, <span class="string">'w'</span>)
set(gca,<span class="string">'FontSize'</span>,20); hold <span class="string">on</span>
errorbar(scaleFactor, mean(rocAreaRGC), std(rocAreaRGC),<span class="string">'o-'</span>, <span class="string">'LineWidth'</span>, 4, <span class="string">'MarkerSize'</span>, 12)
xlabel(<span class="string">'Cone to Midget Ganglion Cell Ratio'</span>)
ylabel(<span class="string">'Classification Accuracy'</span>)
</pre><img vspace="5" hspace="5" src="t_orientedGaborDiscrimination_05.png" alt=""> <p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2015a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% t_orientedGaborDiscrimination
%
% Model cone responses for the experiment on measuring orientation
% discrimination thresholds of an acrhomatic, peripheral Gabor by Marisa
% Carrasco and Jon Winawer.
%
% Script outline:
%     1. Build scene as an achromatic Gabor patch with imageHarmonic.
%     2. Build oi and sensor with specified properties (eccentricity, etc.)
%     3. Loop over 2 stimulus orientations and n trials per orientation
%     4. Within each trial, add eye movements to sensor
%     5. Build the outer segment object with linear filters and compute its
%         response with the sensor structure.
%     6. Sum the response over time for each cone as a cheap way to simulate
%          downstream temporal integration of cone outputs
%     7. Save the cone response as they are time consuming to compute
%     8. From the saved cone file, compute simplified RGC outputs by
%           convolution (DoG) and subsampling
%     9. Compute linear discriminant of stimulus orientation using cone
%           outputs and RGC outputs
%
% JRG/NC/BW ISETBIO Team, Copyright 2015

clear
ieInit

plotConeResponseFlag = true; % plot an example movie of cone responses during one trial
saveConeCurrentsFlag = true;  % save cone responses across all trials (after temporal integration within trials)

%% Specify parameters for contrast values and noise repititions

% Specify angles of Gabor stimulus orientation
angleArr = (pi/180)*[-20 20]; nAngles = length(angleArr);

% Specify retinal location where stimulus is presented (6 deg above fovea)
locationRadius = 6; % degrees of visual angle
locationAngle  = 0; % degrees of polar angle (0 is vertical)

% Number of trials per stimulus condition
nTrials        = 50;

% Eye movement function handle
%   random jitter
fun{1} = @(n) randn(n, 2)*2;
%   directional drift
fun{2} = @(n) (1:n)' * [1 0];
%   square wave oscillation
fun{3} = @(n) square((1:n)/params.n*2*pi*5)' * [1 0];
eyePosFun = fun{1};

% Basic human optics parameters.
oi  = oiCreate('wvf human');

%% Initialize the optics and the sensor

% Set parameters for building the scene/oi/sensor The
% stimulus consists of an achromatic Gabor patch at +/- 20 deg.

% stimulus parameters
%params            = paramsGaborColorOpponent();

params.fov           = 1.5;            % Gabor is windowed with 1.5 deg aperture
params.freq          = 6*params.fov;   % ... and has spatial frequency of 6 cpd
params.GaborFlag     = .25/params.fov; % ... and std of .25 deg
params.nSteps        = 100;            % 100 time steps (1 ms sampling)
params.ecc           = 6;              % 6 degrees eccentricity
params.contrast      = .25;            % Max contrat of 0.25
params.expTime       = 0.001;
params.timeInterval  = 0.001;
params.meanLuminance = 100;

% We build a dummy scene here just so we can subsequently calculate
% the sensor size.  But this scene itself is not used.  Rather we
% build the scene below.
scene = sceneCreate('harmonic', params);
scene = sceneSet(scene, 'h fov', params.fov);


coneP = coneCreate; % The cone properties properties

sensor = sensorCreate('human', coneP, [locationRadius(1) locationAngle(1)]);
sensor = sensorSetSizeToFOV(sensor, params.fov, scene, oi);
sensor = sensorSet(sensor, 'exp time', params.expTime); % 1 ms
sensor = sensorSet(sensor, 'time interval', params.timeInterval); % 1 ms

% This computes with sensor and photon noise
sensor = sensorSet(sensor,'noise flag',2);

%% Loop over two stimulus classes and repeated trials and compute cone responses 

storedConeCurrents = cell(1,nAngles);

for angleInd = 1:nAngles
     % fprintf('\n'); % Comment out for publishing
    
    % We render a new scene for each stimulus orientation (but not for
    % repeated trials for the same orientation). We also pad the scene
    % field of view by factor padFactor so that eye movements do not cause 
    % the sensor to move out of the scence field of view
    padFactor             = 2;
    theseParams           = params;
    theseParams.ang       = angleArr(angleInd);
    theseParams.freq      = params.freq * padFactor;
    theseParams.GaborFlag = params.GaborFlag / padFactor;
    
    scene = sceneCreate('harmonic', theseParams);
    scene = sceneSet(scene, 'h fov', params.fov*padFactor);
    
    % Compute optical image - also computed once per stimulus class (not
    % re-computed for new trials within a stimulus class)
    oi = oiCompute(oi, scene);
    
    % Loop over trials. Each trial gets its own eye movments.
    for trial = 1:nTrials 
        % fprintf('.'); drawnow();  % Comment out for publishing
        
        % Eye position in units of number of cones
        eyePos = eyePosFun(params.nSteps); 
        
        % Loop through frames to build movie
        volts = zeros([sensorGet(sensor, 'size') params.nSteps]);
        for t = 1 : params.nSteps
            
            % Compute absorptions
            sensor = sensorSet(sensor, 'positions', eyePos(t, :));
            sensor = coneAbsorptions(sensor, oi);
            
            volts(:,:,t) = sensorGet(sensor, 'volts');
        end % t
        
        % Set the stimuls into the sensor object
        sensor = sensorSet(sensor, 'volts', volts);
        
        %% Train linear SVM and find cross-validated accuracy
        % Create the outer segment object
        os = osCreate('linear');
        
        % Compute the photocurrent for the whole time series
        os = osCompute(os, sensor);
        coneCurrentSignal = sum(osGet(os, 'conecurrentsignal'),3);
        params.coneArraySize = size(coneCurrentSignal);

        storedConeCurrents{angleInd}(trial,:) = coneCurrentSignal(:);
        
        % visualize cone response for an example trials
        if plotConeResponseFlag && trial == 1
            vcAddObject(scene); sceneWindow;
            
            vcNewGraphWin;
            coneCurrentSignal = osGet(os, 'conecurrentsignal');
            
            subplot(3,1,1)
            imagesc(mean(coneCurrentSignal,3));axis image
            title('Mean cone output across trial');
            for ii = 1:params.nSteps
                subplot(3,1,2)                
                imagesc(coneCurrentSignal(:,:,ii)); axis image
                title('Cone output at single time points');
                subplot(3,1,3)                
                imagesc(volts(:,:,ii));  axis image
                title('Cone voltage at single time points');
                pause(0.1);
            end % nSteps
        end
        
    end
    
end %angleInd


%% Save
coneData = [storedConeCurrents{1}; storedConeCurrents{2}];
labels   = [ones(nTrials,1); -1*ones(nTrials,1)];

dataPth = fullfile(fileparts(which(mfilename)), 'data');

if saveConeCurrentsFlag
    fname = fullfile(dataPth, sprintf('coneResponses%s.mat', datestr(now, 'YYYY-mm-DD_HH.MM.SS')));
    save(fname,  'coneData', 'labels', 'params', 'eyePosFun');
end


%% Classifiy


d = dir(fullfile(dataPth, '*.mat'));
[~,idx] = sort([d.datenum]);

load(fullfile(dataPth, d(idx(end)).name));

% Fit a linear svm classifier between two orientations and calculate
% cross-validated accuracy based on model

% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH first for cone signals REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
m = fitcsvm(coneData, labels, 'KernelFunction', 'linear');
cv = crossval(m,'kfold',5);
rocAreaCones = 1-kfoldLoss(cv);

% REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH then for RGC signals REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
%  RGC hack - bandpass filter and subsample

% RGC is a strucutred array. Each element corresponds to one model of RGCs.
% The model is defined by a spatial receptive field 'rf' and a subsampling
% rate 'ss'. The output of the RGCs are stored in 'data'. The inputs come
% from the cone outputs.
rgc = struct('ss', [], 'rf', [], 'data', []);

% We will make several RGC classes defined by scaleFactor, which will scale
% both the receptive field size and the subsampling rate (the bigger the
% RF, the more coarsely we subsample).
scaleFactor = linspace(2,4,4);
for ii = 1:length(scaleFactor)
    % Center surround RF. The receptive fields have an excitatory center
    % with std of 1 cone * scaleFactor. The inhibitory surround has twice
    % the sd of the center. The cell is balanced, so that the sum of center
    % minus surround = 0. 
    rfCenter   = fspecial('Gaussian', 20,scaleFactor(ii));
    rfSurround = fspecial('Gaussian', 20,2*scaleFactor(ii));
    rgc(ii).rf =  rfCenter - rfSurround;    
    rgc(ii).subsample = scaleFactor(ii);
end

%  Load stored cone data
coneData = reshape(coneData, [], params.coneArraySize(1), params.coneArraySize(2));


%  Loop across RGC types
nBtsrp = 20;
rocAreaRGC = NaN(nBtsrp, length(rgc));
for ii = 1:length(rgc)
    ss  = rgc(ii).subsample;
    rf  = rgc(ii).rf;
    
    % Loop across trials, extracting RGC signals by convolution + subsample
    for trial = 1:size(coneData,1)
        coneCurrentSignal = squeeze(coneData(trial,:,:));
        tmp = conv2(coneCurrentSignal,rf, 'valid');
        tmp = tmp(round(ss:ss:end),round(ss:ss:end));
        rgc(ii).data(trial,:) = tmp(:);
    end
    
    % Classify RGC outputs
    for btstrp = 1:nBtsrp        
        % scrambled = labels(randperm(length(labels)));
        m = fitcsvm(rgc(ii).data, labels, 'KernelFunction', 'linear');
        cv = crossval(m,'kfold',5);
        rocAreaRGC(btstrp, ii) = 1-kfoldLoss(cv);
    end
end

fprintf('ROC Area for cones: %4.2f\n', rocAreaCones)
for ii = 1:length(rgc);
    fprintf('ROC Area for RGC class %d: %4.2f\n', ii, mean(rocAreaRGC(:,ii)))
end

%% Plot classification accuracy as function of convergence ratio
fH = vcNewGraphWin;
set(fH, 'Color', 'w')
set(gca,'FontSize',20); hold on
errorbar(scaleFactor, mean(rocAreaRGC), std(rocAreaRGC),'o-', 'LineWidth', 4, 'MarkerSize', 12)
xlabel('Cone to Midget Ganglion Cell Ratio')
ylabel('Classification Accuracy')


##### SOURCE END #####
--></body></html>